- paralelizem na nivoju ukazov ima svoje omejitve - v praksi dobimo drugačne rezultate od idealnih (izračunanih)
- imamo programe, ki so bolj primerni za te mehanizme in manj primerne (imajo veliko naključnosti)
- večnitnost - program moramo spremeniti (prej je bil cevovod tak, da nismo rabili nič spreminjati):
	- določeni resursi ostanejo skupni
	- če gre ena nit v zgrešitev, se druga nit lahko nadaljuje
	- nit je lahko ali kompletno drugi program, ali pa mi razdelimo en program na več delov
- ![400](../../Images2/Pasted%20image%2020250114102956.png)
- če frekvenco povečamo, bo preveč toplote
- za več CPE ni bilo programov
- daljši cevovod - več stopenj ne pomeni nujno hitrejši izvedbe (max 10 do 20 stopenj)
- večnitnost - pridobimo okoli 30% več zmogljivost in povečamo izkoriščenost jedra

### Paralelizem na nivoju niti
Nit (thread):
- zaporedje ukazov, ki se izvršuje neodvisno
- je lahko del programa (npr. spletni strežni, za vsakega klienta svoja nit) ali samostojen program (bolj redek problem)
- ni več transparentna - program je treba ustrezno spremeniti
- HW podpora:
	- skupni resursi (FE, predpomn, registri) - manj dodatne logike za njihovo delovanje
	- ločeni resurski (reorder buffer, retirement unit (enota za zaključitev ukazov), fetch), tiste stvari, ki je smiselno, da so ločene, jih ločimo

Načini realizacije večnitnosti:
- drobnozrnati pristop (fine grain):
	- hitro preklapljamo med nitmi (vsako periodo)
	- ko nit preklapljamo, rabimo veliko stanja niti shraniti, zato to ni najbolje
	- - zapletena implementacija
	- najbrž se bolj splača pustiti nit, da dela dalj časa
	- idealno bi bilo n-stopenj cevovoda in n niti, da bi bila potem vsaka stopnja neodvisna med sabo (redko v praksi, ker ponavadi želimo, da se en program hitro izvede, ne skupek programov)
- grobozrnata:
	- preklopi redkejši
	- + enostavna implementacija
	- + boljše za manjše število niti (kar je tipična situacija)
	- - več izgub ciklov, ker pustimo niti malo dlje, ne glede na to, če čaka na nekaj
	- se deli na različne izvedbe, nekatere hitreje preklapljajo, nekatere pa počasneje

- niti ne dajamo v rotacijo, če nima nič za delati

- lahko izvajamo več ukazov za različne niti naenkrat:
	- za večizstavitvene CPE
	- AMD SMT
	- Intel HyperThreading
	- hkrati se lahko izvajajo ukazi iz različnih niti - še večja izkoriščenost
	- primer Intel:
		- ![600](../../Images2/Pasted%20image%2020250114105049.png)
		- nekateri viri so skupni, nekateri pa ne

- včasih imamo dve niti, ki hočeta velik del procesorja - se malo stepeta in bi bolje imeti več jeder
- boljše razmerje med pridobljeno hitrostjo in energijsko učinkovitostjo
- manj porabe virov, kot je dejanska pohitritev

CISC:
- iz C programskega jezika pretvorimo v CISC assembly in CPE pretvori v mikroukaze
RISC:
- iz C prevajamo direktno v enostavne RISC-like ukaze

- ukazno pretokovno računanje - ukazi določajo kaj se bo zgodilo in potem CPE direktno to dela
- če ves čas izvajamo neko enostavno operacijo (npr. multiply accumulate pri digitalnem procesiranju signalov (konvolucija)) - kaj če bi celo strukturo CPE prilagodili temu ukazu (HW izvedba):
	- ![150](../../Images2/Pasted%20image%2020250114105820.png)
	- podatkovno pretokovni računalniki - prilagodimo zgradbo podatkom

Maxeler podjetje:
- iz Jave prevede v FPGA (programirljivo vezje, ki ga sestavimo iz nekih gradnikov)
- CPE so bolj učinkoviti če so direktno na siliciju, pri FPGA je nek kompromis, da je lažje za izdelavo

### Paralelizem na nivoju procesorjev (ni na ustnem)

- ne samo več niti, ampak tudi več jeder
- problem kako dejansko izkoritisti več jeder

- več niti, koprocesor
- skupni pomnilnik (po eni strani je veliko ozko grlo, po drugi strani pa omogoča, da procesi na enostaven način komunicirajo med sabo, ker točno vemo, kje v pomn. je nek proces)
- multiračunalniki - lokalni pomnilniki, lahko lažje skaliramo; superračunalniki (gledamo samo zmogljivost) in clusterji za datacentre (hočemo cenejše komponente)
- multiprocesorji - več CPE na enem čipu

- SIMD, MIMD
- skupni in non-uniform pomnilnik:
	- non uniform je hitrejši, ker je lahko bližje procesorju
	- delo s predpomnilniki - različni cache za različne pomn. ali skupni
	- ![400](../../Images2/Pasted%20image%2020250114112940.png)
- stikalna matrika - dražje, kompleksnejša ampak bolj učinkovita realizacija:
	- lahko več dostopov do različnih naprav naenkrat

Kaj se zgodi, ko pišemo v predpomnilnik:
- ali gre takoj v RAM (neučinkovito)
- ali se zapiše šele, ko blok zapusti predpomnilnik (write-back)
- za vsako jedro ločeni predpomnilniki
- snooping predpomn. - kar se dogaja na enem predpomn., je vidno še ostalim:
	- se lahko pretvarja med exclusive in shared predpomn., preklapja med invalid, shared, exlusive in modified stanji

- primer vsote števil na 64 procesorjiv:
	- najprej na vsakem procesorju poračunamo in potem zlijejemo skupaj po deli in vladaj principu

Multiračunalniki:
- ločeni pomnilniki

- najboljša povezava 4D hiperkocka (sosedi med sabo)

Superračunalniki:
- kako narediti čim večji izkoristek
- milijoni jeder

Vega HPC:
- Sling skupnost

Clusters of Workstations:
- Google veliko naredil
- ni state of the art, ampak več redundance s slabšo opremo

- kako razporejamo procese, da je čim večja izkoriščenost

GPU:
- so bolj uporabljene na API nivoju - hitrejši razvoj, ker lahko naredimo čisto drug HW z istim API