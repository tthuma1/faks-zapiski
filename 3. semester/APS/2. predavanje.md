Preverjanje pravilnosti:
- testni primeri:
	- pripravimo vhode in pravilne izhode
	- unit testi
	- lahko naredimo veliko testov, ampak s tem nismo dokazali da naš algoritem pravilno deluje, ker ponavadi ne moremo pokriti vseh možnih vhodov
	- to ni popolno testiranje
	- lažje je pokazati nepravilnost delovanja kot pravilnost
- kaj delamo ko testiramo algoritem?
	- znanstvena metoda - lahko stvari preverimo, testiramo, če dobimo isti rezultat kot tisti, ki je nekaj naredil
	- več eksperimentov (unit testov) kot naredimo, bolj verjamemo, da je hipoteza (da je naš algoritem pravilen) pravilna - ponavadi ne moremo 100% dokazati, da neka hipoteza drži
- formalni dokaz:
	- treba matematično izpeljati, prek lastnosti algoritma pridemo iz lastnosti vhodov do lastnosti izhodov

Sled algoritma (trace):
- algoritem izvajamo na papir ali računalnik in sproti izpisujemo pomembne podatke, kako se spreminjajo tekom delovanja

## Analiza algoritmov

- koliko časa porabimo, da dobimo rezultat
- kako pridemo do nekega rezultata v najkrajšem možnem času
- na kakšen načinu napišemo algoritem, da bo porabil najmanj časa

Viri algoritma:
- analiza algoritmov odgovarja na dve vprašanji:
	- katere vire rabimo za izvajanje algoritma
- kaj so sploh možni viri: čas in prostor
- čas: realni čas, procesorski čas, število operacij (primerjav, dostopov do pomnilnika, ...)
- prostor: poraba pomnilnika (št. celic, bytov)
- energija: poraba električne energije (npr. damo merilec v vtičnico, vemo da je poraba GPU večja in to upoštevamo, ...)
- komunikacija: v porazdeljenih sistemih - pasovna širina, št. paketov
- koliko vira potrebujemo za izvajanje algoritma

- katere in koliko virov potrebuje algoritem za izvajanje v nekem modelu računanja
- model računanja: abstrakten procesor, ki nudi osnovne operacije (plus minus krat...), ene stanejo več kot druge (množenje je dražje kot seštevanje) - štejemo koliko določenih operacij se zgodi
- v realnosti nas zanimajo samo nekatere operacije, ostale pa zanemarimo (rečemo, da je njihova cena 0) - to bo naš model računanja
- v našem modelu računanja bomo veliko stvari zanemarili

Od česa je odvisna zahtevnost algoritma:
- od algoritma samega
- algoritme =skoraj= implementacija
- od modela računanja (odvisno katere operacije zanemarimo), x86 in ARM imata različne ukaze
- od naloge, ki jo podamo (od vhodnih podatkov):
	- velikost naloge: npr. v bitih
	- od podatkov
- odvisnost zahtevnosti od velikosti naloge:
	- množenje 2\*3 vs. 21412\*2312
	- urejanje 2 1 4 vs 4 23 5 654  42 32
	- velikost naloge = n
- časovna zahtevnost: T(n) (funkcija od velikosti naloge)
	- primerjave: T(n) = n-1
- prostorska zahtevnost: S(n):
	- št. pomnilnišlih celic: S(n) = 2n + 3
- odvisnost od podatkov v nalogi:
	- \*1234\*1000 vs. 1234\*5678
	- za nek n gledamo različne naloge - dobimo best, worst, average case
	- npr. ko imamo seznam od 1 do n, ga lahko na n! načinom razporedimo - eni izmed teh seznamov bodo lažji, drugi bodo težji
	- $T_{BEST}(n) <= T(n) <= T_{WORST}(n)$
	- best case (BC), lahko je več best case-ov, zanima nas funkcija za katerikoli best case
	- worst case (WC), lahko je več worst case-ov, zanima nas funkcija za katerikoli worst case
	- povprečni primer: naš algoritem zaženemo za vsak možen vhod in pogledamo povprečno število operacij, $verjetnost * število operacij$, $\sum p_i * o_i$ 
	- avg. case je najtežje ugotoviti
	- poljubni primer je ujet med best in worst case

- najbolj zanimiv v praksi je worst case, ker je avg. case težko izračunati in pogosto je avg. enako kot worst case
	- pove nam največjo možno porabo vira za izvedbo algoritma na katerikoli nalogi
	- garancija, da nikoli ne bo slabše (v realnosti nam to veliko pomeni)
	- za veliko algoritmov je worst case zelo pogost
## Asimptotična zahtevnost

- natančna zahtevnost je pogosto grda in nam niti ne koristi toliko, ker ne rabimo tako natančnih napovedi
- zanima nas samo trend teh operacij, ko se velikost povečuje
- določanje natančne zahtevnosti je težavno v praksi
- v praksi samo ocenjujemo zahtevnost

Asimptotična zahtevnost:
- kaj se dogaja s T(n), ko gre n proti neskončno; gledamo kaj se zgodi pri velikih nalogah
- ocena je "lepa" funkcija (n^2, logn, ...)

- lahko ocenjujemo "grdo" funkcijo od zgoraj, spodaj ali oboje

- O-notacija = zgornja asimptotična meja:
	- bolj pomembno, da je točna pri velikih n, kot pri majhnih n
	- želimo, da bo pri velikih n g(n) > T(n)
	- O(g(n)) je množica funkcij
	- zanima nas tesna zgornja meja - to običajno želimo najti, čeprav je ne znamo nujno vedno

- spodnja asimptotična meja - Ω-notacija:
	- spet imamo eno tesno spodnjo mejo
	- f(n) = Ω(g(n))
- θ-notacija = hkrati zgornja in spodnja meja za neko grdo funkcijo

- da izključimo tesnost: o- in ω-notacija

Tilda (~) notacija:
- kot theta, samo da se ujema še v konstanti
- funkciji naraščata enako hitro
- npr. $5n^3 +2n^2 \~ 5n^3$

- lahko računamo na klasičen način ali z limitami - odvisno kaj je lažje pri danem primeru
- ![400](../../Images2/Pasted%20image%2020241015130510.png)

Uporaba asimptotične notacije:
- opisujemo časovno zahtevnost
- best case in worst case sta lahko komplicirani funkciji
- $T_{BEST}(n) <= T(n) <= T_{WORST}(n)$
- best case ocenimo z omega, lahko tudi s theta
- worst case ocenimo z O ali s theto
- če znamo oceniti best z omega in worst z O, potem lahko ocenimo T(n) -> T(n) = Ω(f(n)) in T(n) = O(g(n))
- če sta O in Ω ista, potem napišemo kar npr. T(n) = θ(n^2)
- vedno rabiš vsaj zgornjo mejo za worst case (O-notacija), zato se O največkrat uporablja