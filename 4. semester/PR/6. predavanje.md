### Vrednotenje modelov

- pri Naivnem Bayesu je bilo dobro, da je preprost za uporabo - lahko z ravnilom merimo razdalje na nomogramu
- nomogram izvira iz medicine, kateri pacienti so rabili neko zdravljenje; na podlagi preteklih podatkov z uporabo nomograma izračunamo verjetnost, da boš dobil neko bolezen
- drevesa so dobra, ker so preprosta
- vse modele gradimo iz podatkov - model je kompresirana predstavitev preteklih podatkov

- pri vrednotenju modelov se sprašujemo:
	- Ali je model dovolj dober za uporabo v praksi? (ali dovolj dobro razloži pretekle podatke)
	- Kateri model je najboljši, če imamo več modelov?

Prekletstvo dimenzioalnosti:
- želimo priti do modela, ki razloži podatke, zato da bomo pri novem primeru lahko napovedali podatke
- želimo:
	- 1. razumeti model (za to so preprosti modeli boljši)
	- 2. točne napovedi
- primer: iz podatkov o očeh ugotovimo, komu ustrezajo katere leče:
- drevo za iris je večje od drevesa za leče, ker imamo več podatkov:
	- če je podatkov več, rabimo večji model, da razložimo vse podatke
	- titanic ima še več vrstic, ampak manj atributov => dobimo bolj kompleksno drevo, ker imamo toliko več vrstic
- če imamo 9 atributov in 300 vrstic:
	- bo še večje drevo => več atributov hitreje poveča drevo kot več vrstic
- radi imamo "suhe" tabele:
	- ![500](../../Images3/Pasted%20image%2020250424113130.png)
	- za vsak atribut moramo imeti čim več vrstic
	- želimo čim boljšo oceno, da se bo nek razred pojavil z neko verjetnostjo - pri bolj suhi tabeli bo to boljši
	- "čim več primerov in čim manj stvari meriti"
- problem pri npr. bioloških podatkih:
	- človeški genom - okoli 30.000 genov, lahko izmerimo, kateri gen je koliko aktiven
	- primer bipolarne motnje:
		- 14.000 atributov, 21 vrstic
	- lahko vzamemo mero signal-to-noise: $\text{S2N} = \frac{|\mu(A) - \mu(B)|}{|\sigma(A) + \sigma(B)|}$ ; A=bipol, B=control
	- s S2N izločimo samo atribute, ki so dovolj pomembni, da dobimo bolj suho tabelo; dobimo npr. 10 atributov in model bo veliko bolj uporaben
	- na podlagi 10 najboljših atributov lahko naredimo npr. gručenje in vidimo, da je precej natančen model
- problem: če začneš z naključnimi podatki, dobiš z metodo S2N model, ki dobro napove naključne podatke => naključnih podatkov se ne bi smelo dati napovedati
- ne moremo zares odpraviti prekletvstva dimenzionalnosti, lahko pa se ga zavedamo
- tudi s prečnim preverjanjem bomo dobili dobro točnost, ker za izbiro atributov s S2N uporabimo že podatke o razredu iz testne množice
- **podatke je vedno treba ločiti na učne in testne!**
- izbira atributov je del modeliranja (S2N)
- atribute lahko izbiramo s pomočjo razreda samo na učni množici
- ocena uspešnosti mora biti nujno narejena na testni množici
- če na ta način naredimo testiranje, vidimo, da je bil naš model za random podatke 50% točen (če bi dobili manj kot 50% bi pomenilo, da podatki niso random in da model napoveduje ravno obratno)