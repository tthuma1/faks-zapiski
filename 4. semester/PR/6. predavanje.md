- pri Naivnem Bayesu je bilo dobro, da je preprost za uporabo - lahko z ravnilom merimo razdalje na nomogramu
- nomogram izvira iz medicine, kateri pacienti so rabili neko zdravljenje; na podlagi preteklih podatkov z uporabo nomograma izračunamo verjetnost, da boš dobil neko bolezen
- drevesa so dobra, ker so preprosta
- vse modele gradimo iz podatkov - model je kompresirana predstavitev preteklih podatkov

- pri vrednotenju modelov se sprašujemo:
	- Ali je model dovolj dober za uporabo v praksi? (ali dovolj dobro razloži pretekle podatke)
	- Kateri model je najboljši, če imamo več modelov?

Prekletstvo dimenzioalnosti:
- želimo priti do modela, ki razloži podatke, zato da bomo pri novem primeru lahko napovedali podatke
- želimo:
	- 1. razumeti model (za to so preprosti modeli boljši)
	- 2. točne napovedi
- primer: iz podatkov o očeh ugotovimo, komu ustrezajo katere leče:
- drevo za iris je večje od drevesa za leče, ker imamo več podatkov:
	- če je podatkov več, rabimo večji model, da razložimo vse podatke
	- titanic ima še več vrstic, ampak manj atributov => dobimo bolj kompleksno drevo, ker imamo toliko več vrstic
- če imamo 9 atributov in 300 vrstic:
	- bo še večje drevo => več atributov hitreje poveča drevo kot več vrstic
- radi imamo "suhe" tabele:
	- ![500](../../Images3/Pasted%20image%2020250424113130.png)
	- za vsak atribut moramo imeti čim več vrstic
	- želimo čim boljšo oceno, da se bo nek razred pojavil z neko verjetnostjo - pri bolj suhi tabeli bo to boljši
	- "čim več primerov in čim manj stvari meriti"
- problem pri npr. bioloških podatkih:
	- človeški genom - okoli 30.000 genov, lahko izmerimo, kateri gen je koliko aktiven
	- primer bipolarne motnje:
		- 14.000 atributov, 21 vrstic
	- lahko vzamemo mero signal-to-noise: $\text{S2N} = \frac{|\mu(A) - \mu(B)|}{|\sigma(A) + \sigma(B)|}$ ; A=bipol, B=control
	- s S2N izločimo samo atribute, ki so dovolj pomembni, da dobimo bolj suho tabelo; dobimo npr. 10 atributov in model bo veliko bolj uporaben
	- na podlagi 10 najboljših atributov lahko naredimo npr. gručenje in vidimo, da je precej natančen model
- problem: če začneš z naključnimi podatki, dobiš z metodo S2N model, ki dobro napove naključne podatke => naključnih podatkov se ne bi smelo dati napovedati
- ne moremo zares odpraviti prekletvstva dimenzionalnosti, lahko pa se ga zavedamo
- tudi s prečnim preverjanjem bomo dobili dobro točnost, ker za izbiro atributov s S2N uporabimo že podatke o razredu iz testne množice
- **podatke je vedno treba ločiti na učne in testne!**

- izbira atributov je del modeliranja (S2N)
- atribute lahko izbiramo s pomočjo razreda samo na učni množici
- ocena uspešnosti mora biti nujno narejena na testni množici
- če na ta način naredimo testiranje, vidimo, da je bil naš model za random podatke 50% točen (če bi dobili manj kot 50% bi pomenilo, da podatki niso random in da model napoveduje ravno obratno)

### Vrednotenje modelov

Kriterija vrednotenja:
- točnost
- razumljivost - najbolj pomembno:
	- odvisna od predznanja osebe, ki gleda model
	- mere:
		- dolžina opisa modela - pri npr. nevronskih mrežah imamo lahko malo uteži (nekaj 100), ampak človeku to ne pove veliko
	- npr. odločitveno drevo je bolj razumljivo, kako se odloča kot za nevronske mreže
	- zdaj se delajo članki, ki ugotavljajo, zakaj nevronska mreža dela tako kot dela - najbrž bodo v prihodnosti tudi nevronske mreže precej razumljive
	- če ne moreš dokazati, da sistem pravilno deluje, lahko riskiraš izgube

Tipi točnosti:
- točnost na učnih podatkih - to ni v redu, ker se je model teh podatkov že naučil (to je tako, kot da bi bil izpit isti kot naloge na predavanjih); ne vidimo, da je povezava med vhodom in izhodom generalizirana:
	- dobro jo je meriti, da preverimo, da se je model naučil pravih stvari; da se je res naučil tistega, kar smo mu dali za učiti (zgornja meja pričakovane uspešnosti na novih podatkih) - če se učiš za izpit je težko pričakovati, da boš na izpitu boljši kot si bil doma pri reševanju nalog
	- pri nevronskih mrežah se gleda loss factor; v vsakem trenutku lahko vidiš, kako dobro opisuje podatke, ki jih je videl na vhodu; izguba pada z iteracijami (točnost narašča) - gledaš kako točno znaš sploh opisati učne podatke
- točnost na novih (testnih) podatkih - to nas najbolj zanima:
	- en del podatkov je treba dati na stran čisto na začetku

- koliko podatkov dati v učno in koliko v učno množico:
	- želimo čim bolj "suhe" tabele za učenje in želimo veliko testov, da bolje ocenimo točnost

- v testno množico lahko dodamo tudi nek zunanji dataset, ki je dovolj podoben
- ![600](../../Images3/Pasted%20image%2020250424123257.png)

- če imamo n vrstic, je število možnih prečnih preverjanje (št. možnih delitev) enako $2^n - 1$ (za vsako vrstico se odločimo ali je v eni množici ali v drugi)

Intervali zaupanja ocene točnosti:
- rečemo, da je točnost med 60% in 80% => velik interval in ne vemo zares, katera meja je bližje pravemu rezultatu:
	- ponavadi vzamemo spodnjo mejo, da vemo worst case
- tudi v projektu, ko ocenjuješ uspešnost modela, naredi interval zaupanja, namesto samo ene številke
- interval zaupanja dobimo tako, da večkrat ponoviš grajenje modela nad različnimi delitvami testni in učne množice:
	- izmed vseh modelov vzameš npr. sredinskih 93% točnosti
	- bolj je model stabilen, ožja bo razlika med spodnjo in zgornjo mejo

Sheme vzorčenja:
- k-kratno prečno preverjanje (k-cross validation, k-CV), npr. 3-kratno prečno preverjanje:
	- zakaj na začetku naključno premešati vrstice? lahko vzamemo random tretjine ali pa na začetku random premešamo vrstice in vzamemo tretjine eno za drugo
	- delitev mora biti naključna, ampak vsaka podmnožica mora biti podobna vsem podatkom - "stratified sampling":
		- npr. če je na vseh podatkih 90% enega razreda, mora biti tudi v vseh foldih 90% tega razreda
		- načeloma bi morale biti tudi vrednosti atributov enakomerno razdeljene, ampak v praksi se to pri random premešanju ne zgodi dovolj pogosto
	- ne gradimo enega modela, ampak zgradimo k modelov - se med sabo malenkost razlikujejo
	- da bi dobili interval zaupanja, bi rabili npr. 100-krat narediti 3-kratno prečno preverjanje
- 70%:30%:
	- 70% naključnega izbora je učna množica, 30% testna množica
	- če hočemo interval zaupanja, rabimo to spet večkrat ponoviti (npr. 100-krat)

Mere kalibracije in razločevanje:
- kalibracijske mere:
	- ko npr. delamo meter, rabimo vedeti, kako dolg je meter
- razločevalne mere:
	- ko npr. delamo meter, primerjamo ali je daljši od nekega drugega
- nek klasifikacijski model na vrne razred X in verjetnost za razred X (in za vse ostale razrede) - model "izmeri" verjetnost, da primer pripada razredu 
- 