Napovedovanje vrednosti v matriki:
- včasih imamo redke matrike z manjkajočimi podatki, ker je neka meritev npr. draga; npr. pri ocenah filmov če nek uporabnik ni ocenil enega filma, ga pač še ni pogledal
- če imamo zelo redko matriko, ne moremo reči, da so to 0, ker bo potem model mislil, da so tam dobesedno 0 - namesto tega, moramo manjkajoče vrednosti preskočiti (preskočimo tisti `[i, j]`)
- če smo dali 0 v eno celico, bo model še vedno skoraj enako natančen - model je dobro odstranil šum
- s tem lahko najdemo potencialno problematično probleme, ki jih naš model ne zna dobro opisati - način detekcije osamelcev :
	- iskanje odstopanj podatkov od modela (napake oz. osamelci)
	- $|X - W \cdot H|$ => pogledamo celice, ki imajo tu največjo absolutno vrednost
- napovedovanje novih vrstic (ali stolpcev) v matriki:
	- $X \approx W \cdot H$ => originalni podatki
	- $X_2 \approx W_2 \cdot H$
	- $H_2$ je enak $H$, ker se stolpci niso nič spremenili, smo samo dodali vrstice
	- $W_2 = \frac{X_2 \cdot H^T}{W \cdot H \cdot H^T}$

Primer Netflix:
- redka matrika ocen 100 milijonov od 8.5 milijard => 0.04%
- Netflixov stari sistem je imel RMSE = 0,9514
- problem z osebnimi podatki - iz ocen filmov se je dalo identificirati anonimizirane uporabnike
- zmagovalni ni bil samo en model matrične faktorizacije, ampak je bil ansambel 100 modelov
- obstajajo pristranskosti (bias):
	- različni ljudje različno strogo ocenjujejo
	- pristranskost se da ugotoviti iz podatkov tako, da primerjamo ocene enega uporabnika s povprečjem
	- pristranski niso samo uporabniki ampak tudi filmi - popularne filme bo gledalo več ljudi in ponavadi bodo dobili boljše ocene
	- $X \approx W \cdot H + B_1 + B_2 + ...$
	- $B_i$ = pristranskost
	- ko dodamo pristranskost, naredimo bolj kompleksen model in je nevarnost, da se preveč prilagodi učni množici
- dodatni podatki o uporabnikih:
	- Netflix ima še neke demografske podatke, ki bi jih lahko uporabili za boljšo napoved - to ni bilo javno, ampak nam veliko pomaga, ker imajo demografsko podobni ljudje običajno podobne preference (npr. otroci imajo radi podobne filme in stare mame imajo rade podobne filme)
- lahko dodamo podatek, kdaj je bila podana neka ocena, ker se pristranskost lahko spreminja skozi čas - dobimo 3D matriko (tenzor):
	- $X(t) \approx W \cdot H(t) + B_1(t) + B_2(t) + ...$
- časovna dinamika:
	- nek film se splača predlagati medtem, ko mu gledanost raste, ne takrat ko stagnira
	- ko gledanost stagnira, pomeni, da so si vsi, ki so želeli videti ta film, to že naredili => takrat ga ne predlagaj

Priporočilni sistemi:
- content filtering:
	- na podlagi vsebine oz. opisa predmetov
	- atributni opis predmetov
	- npr. Pandora za glasbo naredi "music genome", da vsak komad skuša opisati z nekimi atributi - to je težko, časovno potratno
	- uporabniku priporočaš predmete, ki imajo podobne atribute, kot predmeti, ki jih je kupil prej
	- težava: pridobivanje opisov
- collaborative filtering:
	- na podlagi ocen ostalih uporabnikov
	- to je hitreje, lažje
	- te ne zanimajo, kakšni so dejanski predmeti, ampak samo ocene drugih uporabnikov
	- ugotoviš, kateri uporabniki so našemu uporabniku najbolj podobni
	- rabiš dovolj veliko uporabnikov - ko začneš jih nimaš:
		- problem "hladnega zagona", prazna matrika ocen na začetku
- content + collaborative (mešanica):
	- collaborative je matrika X, content so opisi uporabnikov (demografski podatki, ki jih uporabniki sami vnesejo, da ne rabimo strokovnjakov, ki bi iskali te podatke)
- iz matrik $W$ in $H$ lahko delno vidimo, kako imajo filmi vzorce glede na to, ali je usmerjen v moške/ženske, ali je moški/ženska v glavni vlogi, ali je resen/fantazijski film itd.

NMF - nenegativna matrična faktorizacija:
- $X_{i,j} \geq 0$
- $W, H \geq 0$
- podatki nenegativni => model tudi nenegativen
- nenegativnost pripomore k boljši razumljivosti modela
- model je "aditiven" - rezultat sestavimo tako, da komponente seštevamo skupaj

Redukcija dimenzionalnosti:
- PCA:
	- ima tudi odštevanje rezultata, ne samo prištevanje
	- odkrije povprečno komponento in odstopanja v + ali - (težje razumeti)
- NMF odkrije komponente v podatkih:
	- dobro za besedila, ker neke besede ne moreš malo prišteti in malo odšteti, ampak samo je ali ni v besedilu
- dela samo z normalno porazdeljenimi podatki:
	- če imamo drugo porazdelitev, jo moramo normalizirati

### Zlivanje podatkov (data fusion)

- podobno kot prej pri Netflix-u - ko imamo več podatkov, ki so raznoliki, se nam jih v večini primerov splača uporabiti
- hkratna faktorizacija več matrik podatkov
- lahko samo staknemo matrike skupaj
- $W_i$ mora biti v vsaki matriki enak, da vsakega uporabnika vedno opišemo na enak način
- relacije med objektnimi tipi (filmi)

- matirčna (dvo)-faktorizacija:
	- $X \approx W \cdot H$
- matrična tri-faktorizacija:
	- $X \approx G_i S_{ij} G_j^T$
	- $X$ je relacija med objekti tipa i in j (i in j sta objektna tipa - filmi, knjige ...) (v našem primeru sta i in j uporabnik in knjiga)
	- $G_i$ = preslikava objekta tipa i v latentni prostor i
	- $G_j^T$ = preslikava tipa j v latentni prostor j
	- $S_{ij}$ = preslikava med latentnim prostorom i v j (uporabnike preslika v knjige)
- za vsak objektni tip se lahko odločimo, v koliko dimenzionalni prostor ga preslikamo - eni objektni tipi rabijo več dimenzij, da se lepo ločijo kot drugi