- vmesno poročilo:
	- osnovna statistika, vizualizacije
	- kje so osamelci, kaj šteješ pod "večino" podatkov
	- kako je bilo treba podatke transformirati
	- ali so bili podatki uporabni ali ne
	- raje manj napisano in da slika več pove
	- ali je preveč podatkov in bomo morali delati vzorce
- končno poročilo:
	- v streamlit predstaviš glavno stvar, ne nujno vse, kar si naredil

- pri hierarhičnem gručenju združujemo od spodaj navzgor
- pri k-means probamo zajeti podatke, ki so najbolj skupaj 

- problem koliko skupin imamo:
	- pri hierarhičnem gručenju

- če večkrat poženemo k-means dobimo različne skupine, odvisno od postavitve centroidov:
	- rešitev: večkrat poženeš k-means in poiščeš konsenz
- pri hierarhičnem gručenju dobimo samo neko drevo:
	- problem je, da je lahko šum v podatkih - slučajno sta dva primere najbližje, čeprav ne spadata zares v isto gručo

- zanesljivost gručenja, v povezavi s šumom v podatkih:
	- pri k-means poženemo večkrat in pogledamo konsenz; izvor nezanesljivosti je random inicializacija
	- pri hierarhičnem gručenju dobimo eno drevo in ni zares nobenega konsenza
- obe metodi gručenja se poslabšata zaradi šuma v podatkih - vpliv lahko zmanjšamo z bootstrapom:
	- na podatke gledamo na različne načine
	- uvedemo naključnost v funkcijo razdalje
	- ponavljamo s spremenjenimi razdaljami med primeri
	- dosežemo konsenz
	- dendrogram ti bo povedal, kolikokrat se je pri iteracijah zgodila neka prikazana ta delitev med n ponovitvami
	- moramo npr. 100-krat ponoviti gručenje

- kako merimo razdaljo:
	- kosinusna razdalja je bolje za visokodimenzionalne podatke
	- velikokrat uporabimo Evklidsko razdaljo

- linkage:
	- min -  ko nočemo, da se stvari prekrivajo
	- max - ko nam je vseeno, če se stvari prekrivajo, ker nas zanimajo ekstremi
	- avg - ko ne vemo zares, kaj hočemo dobiti - skupino so še vedno dovolj narazen in se ne prekrivajo preveč
	- wardovo združevanje:
		- zagotavlja da so pripadniki gruče čim bolj enako podobni med sabo
		- podobnost je lahko precej velika, ampak če so si vsi enako podobni, potem je to dobro
		- dobro ko imamo eno področje, kjer so primeru blizu skupaj in področje, kjer so primeri daleč narazen
		- različno "gosta" področja primerov ga ne zmotijo, medtem ko npr. k-means to zmoti
		- npr. imaš smučarje, ki kupujejo podobne stvari in ljubitelje narave, ki so si sicer podobni, ampak so podobnosti bolj narazen

Kvaliteta gručenja:
- kakšen mora biti dendrogram, da rečemo, da je gručenje dobro:
	- spodaj so gruče čim bolj skupaj (čim manjša razdalja znotraj gruče), zgoraj je razdalja med gručami čim večja (čim večja razdalja med gručami) - rečemo, da je oblika metle/grabelj s čim manjšimi ščetinami

Mere kvalitete gručenja:
- 100+ različnih mer
- vsaka mera je predlagana na podlagi nekih predpostavk nad podatki, ampak ko dobiš neke podatke ne veš, katera je zares najboljša
- če ničesar ne veš o podatkih, je najboljša ocena silhuetni koeficient
	- $S_i = \frac{b_i - a_i}{max(a_i, \; b_i)}$
	- $a_i =$ razdalja do pripadnikov iste gruče kot je vzorec i
	- $b_i =$ razdalja do najbližje gruče
	- a = neka gruča, b = najbljižja druga gruča
	- i = vzorec
	- ko bo razdalja do pripadnikov isto gruče kot je vzorec i čim manjša bistveno večja kot razdalja do najbližje gruče
	- $-1 \leq S_i \leq 1$
	- želimo, da je $S_i$ čim bližje 1, če je $S_i$ negativen, pomeni, da tisti vzorec ne sodi dobro v dano skupino
	- $S = \frac{1}{n} \sum_{n}{S_i}$
	- S = povprečje vseh silhuetnih razdalj
	- 