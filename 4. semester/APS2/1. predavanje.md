- algoritmi = postopki
- podatkovne strukture (PS) = kako shranjujemo podatke v računalniku, konstruktu v računalniku, ki nam omogoča shranjevanje podatkov v računalniku
- da lahko naredimo in uporabimo podatke v dani PS, rabimo neke algoritme
- algoritmi vedno uporabljajo podatke, ki jih moramo nekam shraniti

- želimo, da je algoritem kakovosten oz.:
	- pravilen in
	- učinkovit

- pravilnost:
	- skoraj vedno pravilen rezultat (npr. generator praštevil za kriptografski algoritem ne vrne čisto vedno praštevila)
	- skoraj pravilen rezultat (npr. trgovski potnik - dobimo čim cenejšo pot, ampak najbrž ne najcenejšo; barvanje grafa)
	- vedno popolnoma pravilen rezultat (npr. avtonomna vozila)
- učinkovitost:
	- količina porabljenih virov (čas, prostor, porabljena energija, pasovna širina)
	- učinkovit algoritem porabi manj virov

Zakaj nas zanima časovna zahtevnost:
- da hitreje pridemo do rezultata
- kadar algoritem poženemo večkrat, želimo, da traja čim manj časa (če bomo 1ms ali 2ms pognali 10000-krat, bo razlika)
- v kakšni enoti merimo čas izvajanja:
	- število operacij, korakov
	- št. ciklov procesorja
	- za algoritem za urejanje npr. število primerjav in zamenjav
- zanimajo nas parametri, ki opisujejo nalogo:
	- npr. za tabelo nas zanima velikost tabele (n); lahko bi za urejanje gledali koliko je trenutno tabela urejena (mogoče imamo manj dela z že urejenimi tabelami)
- želimo funkcijo, ki dane vrednosti parametrov preslika v število korakov

Približno ocenjevanje časovne zahtevnosti:
- natačno število korakov je težko oceniti
- zadovoljimo se z oceno zgornje meje (določitev velikostnega reda)
- simboli:
	- $\Theta$ = velikostni red, točno toliko, najbolj natančno; v bistvu gleda worst case; npr $\Theta(n^2)$ pomeni, da če mu damo tabelo velikosti n, bo naredil približno $n^2$ operacij (krat konstanta)
	- $O$ = zgornja meja; npr. naredil bo kvečjemu $n^2$ operacij; je lahko manj natančno, ker $O(n)$ = $O(n^2)$, samo vemo od česa ni slabši, ne vemo pa točno kako dober je, včasih ne znamo natančno določiti:
		- primer gradnja kopice: očitno je $O(n\space logn)$, boljša analiza nam pokaže, da je v bistvu $\Theta(n)$ (samo en element pogreznemo $lg(n)$ globoko, večino vozlišč zelo malo ugreznemo)
	- $\Omega$ - spodnja meja:
		- kadar želimo, reči, da algoritem ne bo delal hitreje kot to
		- npr. problem urejanja je $\Omega(n \space logn)$, če elemente primerjamo med sabo; različni napredni algoritmi za urejanje se razlikujejo po konstanti, vsi pa imajo $\Omega(n \space logn)$ - želimo algoritem, ki ima poleg dobre asimptotične zahtevnosti še majhno konstanto 