- pri APS pogosto delamo analizo worst case, čeprav se včasih worst case redko pojavi

Amortizirana analiza:
- dobiš bolj pravične, realne rezultate
- primer z razširjennim skladom
- Amortizirana analiza – pristop k ocenjevanju zahtevnosti algoritmov in podatkovnih struktur
- Pogosto se zgodi, da je “worst-case” analiza (po krivici) preveč pesimistična
- ocenjuje celoto, ne samo eno operacijo (lahko je ena operacija zelo draga, ampak če se bo izvedla malokrat, potem je v celem zaporedju večina operacij prijaznih, ena je pa draga), zanima nas kako je v povprečju (upošteva drage operacije, ampak jih porazdeli med ostale poceni operacije, ne pa da drage prevladajo)
- vedno se bomo ukvarjali z zaporedjem n operacij
- vzame vse operacije, ki se lahko zgodijo in vzame povprečje tega

- ![600](../../Images3/Pasted%20image%2020250225092309.png)
- metoda vsote:
	- ![600](../../Images3/Pasted%20image%2020250225092336.png)

Abstraktni podatkovni tip:
- imaš opis, nimaš konkretne implementacije (opis podatkov + operacije nad podatki)
- ADT + implementacija = podatkovna struktura (PS)
- v Javi:
	- ADT je vmesnik (interface)
	- primer Set ADT (interface), podatkivni strukturi `TreeSet` in `HashSet` (`class HashSet implements Set`), ne moreš reči `new Set()`
- brez implementacije ne vemo zares, koliko stane neka operacija

Tabela (polje):
- ![400](../../Images3/Pasted%20image%2020250225104141.png)
- za get in put imamo sintakstični sladkor z \[\]
- `PosplošenaTabela`:
	- sama ve, kje je konec tabele in lahko delamo npr. `insert(x)`
	- ![600](../../Images3/Pasted%20image%2020250225104402.png)

Dinamična tabela:
- ko delamo insert, se lahko poveča
- tabele so v pomnilniku neprekinjen blok podatkov
- ko hočemo povečati tabelo, najbrž ne bomo dobili dovolj praznega prostora takoj naprej od tam, kjer smo => rabimo prej poiskati dovolj velik prazen prostor nekje v pomnilniku
- insert bo rabil kopirati celo tabelo
- povečevanje krat 2 - to je optimalno povečevanje

- v urejeni tabeli je insert in delete drag, ker rabimo odrivati vse elemente - je dobra če na začetku napolnimo tabelo in potem samo delamo veliko find-ov
- ![600](../../Images3/Pasted%20image%2020250304085303.png)

Tabela tabel (cascading arrays):
- podatke hranimo v večih tabelah
- imamo tabele velikosti 1, 2, 4, 8 ...
- vsaka tabela je lahko prazna ali polna (ne more biti na pol polna)
- podatki v posamezni tabeli so urejeni
- ali lahko hitro iščemo elemente?
	- pogeldati moramo v vse tabele ($O(lgn)$ tabel) 
	- v vsaki tabeli iščem z dvojiškim iskanjem ($O(lgn)$)
	- skupna cena iskanja = $O(lgn \cdot lgn) = O(lg^2n)$
- ![500](../../Images3/Pasted%20image%2020250304094202.png)

Slovar:
- ključ, vrednost pari
- element bomo implementirali kot razred:
```
class Elt {
	int key;
	Object value;
}
```
- insert(S, e) -> S
- find(S, key) -> elt
- delete(S, key) -> S

- kaj se zgodi, če dvakrat kličemo insert(S, e) => drugi klic se ignorira
- lahko imamo samo ključe in null vrednosti za value povsod - dobimo množico ključev in na vsak ključ je pripeta null vrednost:
	- slovar je v bistvu razširitev množice, kjer je vsakemu elementu pripet še value
- veliko izvedb z različnimi podatkovnimi strukturami:
	- ![500](../../Images3/Pasted%20image%2020250304101154.png)

Seznam:
- ni nam všeč, da je find $O(n)$ - ali bi kaj izboljšali, če imamo urejen seznam?:
	- nič se ne izboljša