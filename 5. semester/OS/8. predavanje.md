- zadnjič smo delali kNN collaborative filtering, danes bomo malo drugače collaborative filtering
- Pearsonov koeficient nam je lepo uravnotežil dejstvo, da eni ocenjujejo bolj strogo kot drugi
- zadnjič smo delali primerjavo med vrsticami - za mnenje vprašaš tiste, ki imajo podoben okus kot ti
- lahko delaš tudi primerjavo med stolpci - računamo podobnost med izdelki:
	- ne primerjamo lastnosti izdelkov, ampak ratinge izdelkov
	- filmi so si podobni, če imajo podobne ocene
	- izberemo k najbolj podobnih izdelkov, ki jih je naš uporabnik že ocenil
- v naši tabeli imamo veliko neocenjenih celic, ker je preveč izdelkov, da bi jih vsi ocenili
- želiš imeti tabelo, ki ima veliko vrstic in malo stolpcev (veliko uporabnikov in manj izdelkov), zato da imaš statistično moč za napovedmi:
	- ko smo računali podobnost med uporabniki, primerjamo vse stolpce uporabnikov - stolpcev je manj kot vrstic
	- če primerjamo izdelke, potem za vsak stolpec primerjamo cel vektor stolpca - teh ocen bo v splošnem več; ko primerjamo dva izdelka med sabo, bo več možnosti, da je nek uporabnik ocenil oba izdelka, ker iščeš med veliko uporabniki; imeli bomo več parov, kjer je en uporabnik ocenil film X in Y
	- ko dobimo novo oceno, bomo pri primerjanju vrstic najbrž bolj vplivali na napoved, ker smo napoved delali na podlagi manj parov; pri primerjanju stolpcev pa bomo dobili manjši vpliv, ker imamo že veliko parov

- item-to-item je bolj stabilno na prihod novih ocen
- hitrosti izračuna med user-to-user in item-to-item ni zelo velika, ker rabiš pri vseh pogledati celo tabelo
- če hočeš hitrejše izračune, uporabiš cache - offline izračunaš del napovedi:
	- pri item-to-item se rabijo podobnosti med delovanjem manj spreminjati, torej jih lahko tudi pustiš iste in potem ko je sistem najmanj obremenjen (offline) narediš en velik update vseh napovedi
	- v realnem času ne moreš delati dovolj hitro napovedi, zato delaš offline update napovedi

- za podobnost med izdelki uporabi adjusted cosine similarity
- od tu naprej vzameš filme, ki so si dovolj podobni (imajo dovolj velik similarity), da iz njih napoveš oceno
- izdelki nimajo svoje bazične "strogosti", zato tu ne rabiš ocene začeti z baseline + uteži\*ocene, ampak narediš samo uteži\*ocene (utež bo večja, če je večji similarity)

- user-to-user je bistveno bolj podvržen na napade na priporočilne sisteme z bot accounti, ker je manj odporen na spremembe:
	- pri item-to-item bodo bot accounti naredili manj škode, ker vsak nov rating manj vpliva na napoved (item-to-item je bolj stabilen)

Slope one metoda:
- dobro za cold start, ko imaš malo število ratingov
- tabela je zelo prazna (to ni cold start v pomenu, da nimam uporabnikov ali da nimam izdelkov, ampak da imam že uporabnike in izdelke, ampak še nimam veliko ocen v tabeli)
- ko imamo malo ocen v tabeli, bo malo istoležnih parov (četvorčkov), zato bomo imeli v Pearsonovem koeficientu malo števil (statistično šibko) - tu ne iščemo istoležnih parov, ampak rabimo samo trojčke, ki jih bo več, zato bomo imeli večjo statistično moč
- računamo razliko med dvema ratingoma enega uporabnika - dobimo slope (naklon) na tistem mestu
- podobno kot naključni gozd - imamo veliko komaj nadpovprečnih dreves in ko jih pogledaš skupaj, dobiš dober rezultat
- dobimo trojček, ko dodamo še našega aktivnega uporabnika (uporabnika za katerega napovedujemo):
	- če smo izračunali razliko med oceno I1 in I2, potem rabi aktivni uporabnik oceniti I1 in iz tega dobiš napoved I2
- imaš neodvisne ocene - če vedno sprašuješ istega weak learnerja, boš vedno dobil isti odgovor - tu imaš raznolikost, saj so uporabniki neodvisni med sabo:
	- podobno kot če pri naključnih gozdovih ne bi vedno uporabil učnih podatkov
	- vsaj nekaj informacije je v vsakem drevesu (nad 50% CA)
- vseeno nam je za podobnost med uporabniki, ampak želimo, da iz veliko trojčkov dobimo nekaj smiselnega

### Implicitni ratingi

- namesto ocen 1 do 10 imaš like/dislike ali kakšno drugo akcijo, ki ti implicitno pove, kako bi nekdo nekaj ocenil
- npr. pri gledanju TV, če gledaš oddajo 5 minut in preklopiš stran, potem je to dislike; če pogledaš 80% oddaje, potem je to like
- lahko imaš samo like, brez dislike:
	- še vedno imaš dva razreda - ni ocene in like

- povezovalna pravila:
	- izvira iz nakupovalne košarice
	- support (podpora/coverage) = pogostost uporabnosti pravila (koliko primerov znotraj baze nam pokrije to pravilo)
	- zaupanje (confidence/accuracy) = če uporabim to pravilo, v koliko primerih bom imel prav