- vabljeno predavanje
- collaborative filtering (user-based, primerjaš uporabnike med sabo) in metadata based (item-to-item, itemom dodaš opise, kakšne lastnosti imajo; ugotoviš, da en uporabnik npr. rad gleda grozljivke, en pa risanke)
- lahko tudi hibridno collaborative in metadata based
- recall@k - kolikokrat si zadel priporočilo v prvih 10 priporočilih, kolikokrat v prvih 30 priporočilih, kolikokrat v prvih 100

- lahko se ti zgodi, da imaš en item v bazi večkrat z rahlo različim metadata
- query phase, rerank phase, online (ko imaš deployan), offline (ko gradiš model) workflow
- offline query:
	- iz npr. 500.000 itemov na hitro, cheap, grobo izločiš najboljših npr. 10.000
	- v offline rerank na teh ostalih uporabiš nek bolj resen algoritem
- learn to rank algoritmi:
	- za filme veš, katerega je uporabnik kliknil in vse, ki so bili priporočeni (cel stripe filmov)
	- vsi, ki so bili prej rankani pred tem, ki je bil zares kliknjen, so narobe (negativno označeni), tisti, ki so bili napovedani za tistim, ki je bil kliknjen, so v redu (pozitivno označeni) - tisti, ki je bil zares kliknjen, bi moral biti na prvem mestu v stripu

Two-tower algoritem:
- http://shaped.ai/blog/the-two-tower-model-for-recommendation-systems-a-deep-dive
- nevronska mreža
- query tower in item tower predstavljata input
- query:
	- device, time, gender, user ID ...
- item:
	- genre, running time, actors, item ID ...
- vsak izmed towerjev se ločeno embedda, na koncu za vsak tower dobimo vektor k parametrov
- nato narediš dot product teh dveh vektorjev dolžine k - večji kot bo bil na koncu skalar, boljši je similarity
- ![600](../../Images4/Pasted%20image%2020251219132704.png)
- izziv - ko dodaš nov film, ki ga še noben ni pogledal, ti bo koristil samo item tower (query tower je prazen) - rabiš iz metadata filma gledati, kdo bo želel to gledati
- izziv - ko pride nov uporabnik - query tower bo prazen
- problem, da si uporabniki delijo profile - vseeno vemo, da npr. v petek zvečer ljudje ponavadi gledajo filme, v soboto zjutraj pa risanke, zato vseeno veš, kaj je bolje priporočiti
- ko dobiš similarity, veš kateremu filmu iz baze je tvoj query najbolj podoben - iz tega narediš kNN po filmih iz baze:
	- za kNN ti prav pridejo vektorske baze, ki izračunajo vektorski indeks (HNSW) - ti zelo zmanjša prostor, ki ga moraš iskati za kNN
	- namesto da tvoj similarity primerjaš z embeddingi vseh filmov, ga primerjaš samo z embeddingi filmov, ki so blizu - veliko hitreje
- embeddinge za iteme si lahko vnaprej poračunaš
- če želiš npr. samo božične filme, ti baza to hitro sfiltrira

- recommender želiš posodabljati, ker se preference uporabnikov skozi čas spreminjajo:
	- nov model bo minimalno spremenjen, zato nočeš trenirati vsega from scratch, ampak staremu modelu samo dodaš učenje na podatkih novega tedna
	- ne želiš se overfittati na nove podatke
	- pri updatanju mreže si moraš poleg trenutnih uteži zapomniti tudi zadnje stanje učenja (gradiente), ker sicer dobiš dosti random rezultate

- ne želiš recommendati več stvari, ki so zelo podobne (npr. več delov ene franšize filmov) ali pa nočeš več vsebin iz enega TV programa hkrati napovedati, ampak želiš vmes dati še vsebine drugih TV programov