- status quo trap:
	- good enough, tudi če imaš izbiro, da zamenjaš svojo odločitev za neko boljšo, je ne boš zamenjal, ker se ti ne da (vseeno rabiš nekaj efforta, čeprav zelo malo)
	- hočeš, da stvari ostanejo tako, kot so sedaj
	- sledi stanju, ki trenutno obstaja
	- npr. če kupuješ delnice, kupiš tisto, ki ti jo nekdo predlaga, brez da bi se pozanimal o ostalih možnostih, ker bi za to rabil effort, in ker je tista ponujena najbrž good enough
	- npr. pri menjavi telefonskega operaterja, ti novi operater hoče olajšati prehod k njim, da je čim manj efforta - če je efforta preveč, se nobenemu ne bo dalo iti k tebi, tudi če si ti boljši
	- npr. prvi avti so bili podobni kočijam, električne polnilnice izgledajo enako kot bencinske, prvi elektronski novičniki so imeli isti dizajn kot fizični
	- npr. pri senatu, ko nekaj predlagaš, prevzameš odgovornost za posledice nase; če si tiho, nimaš nobene odgovornosti
	- kako se izognemo tej pasti:
		- se zavedamo in vložimo effort
		- ni nujno, da je alternativa res boljša - lahko ugotovimo, da je status quo prava izbira

### Hibridizacija priporočilnih sistemov

- podobno kot ensamble pri machine learning - random forest, gradient boosting, kjer vsak model glasuje
- hibridiziramo prvi del priporočilnega sistema, ki nam da številčni output (engine, brez šminke)

Monolitni hibridi:
- priporočilni sistem
- še vedno imaš monolitni sistem (ena celota, brez koščkov)
- recommenderji znotraj monolita bodo še vedno videti kot ena celota
- vhodi se bodo zgrupirali na notranje sistema oz. ustrezno preprocesirali

Paralelni hibridni:
- nimamo enega recommendeerja, ki ga spremenimo, ampak imamo več recommenderjev, kjer ima vsa svoj input (lahko imajo isti input)
- na nek način združimo rezultat
- to je isto kot random forest

Zaporedni hibridni (pipeline):
- kot XGBoost in ADABOOST
- vsak naslednji recommender dobi za vhod izhod iz prejšnjega (zraven lahko pomešamo še originalen input)
- prvi naredi neko napoved in potem naslednji recommender popravi napoved od prejšnjega
- prvi recommender je lahko hiter (hitra začetna selekcija, ima manj znanja in je manj kvaliteten), naslednji pa počasen (na podani grobi izbiri delamo počasen, natančen recommender, ki je v bistvu dovolj hiter, ker ima veliko manj primerov, med katerimi lahko izbira)

- kombiniranje featurejev

Primer v zvezku (monolitni sistem):
- A = aktivni uporabnik
- navigation - po katerih straneh si gledal
- view - uporabnik je kliknil na izdelek in ga zdaj gleda - velika verjetnost, da mu je bila ta stvar všeč, da je pritegnila njegovo pozornost
- context - k = keyword (kaj konkretno si iskal - si spet moral izraziti ekspliciten trud, torej ti je to najbrž všeč)
- buy - najmočnejša možna podpora, če si nekaj kupil, ti je skoraj zagotovo všeč (se dogaja šum - lahko si kupil za prijatelja)
- nav < view < context < buy
- na tem lahko uporabimo collaborative filtering - kateri uporabniki so podobni trenutnemu uporabniku
- podobnosti ne smeš računati tako, da ti je vsak stolpec enako vreden, ampak je buy stolpec najbolj vreden, ostali pa manj
- lahko najprej iščeš po buy in če ni ujemanj greš na ctx itd.
- lahko utežiš vsak stolpec, npr. buy = 10, ctx = 5 ...
- imamo informacije, ki niso enako močne
- koliko je sistem stabilen:
	- buy se ne dogajajo pogosto - ko nekaj novega kupimo, močno spremenimo recommender - pri tem želimo hiter update, pri ostalih spremembah pa npr. tedenski update

Primer monolit 2:
- P_A,user = podobnost med uporabniki, že izračunano (collaborative filtering je zadaj glavni algoritem)
- n_user = koliko ratingov je ta user že dal (več kot jih ima, bolj ga poznamo)
- n_A,user = koliko ratingov je skupnih med A in drugim uporabnikom - ko imamo veliko skupnih ratingov, bo korelacija bolj močna
- čeprav je 0.8 večja podobnost od 0.7, je z drugim uporabnikom več skupnih ratingov, kar nam pove, da je ta podobnost bolj točna
- utežimo s podobnostjo in n_A,user:
	- naredimo cutoff, npr. do 50 skupnih ratingov, podobnost ni zelo točna, potem pa je statistično že v redu
- r_user,itemX = nek predviden rating, ki ga je dal en drug recommender - iz napovedane ocene napovedujemo oceno (prva napovedana ocena je izračunana iz podobnosti U2 ostalim uporabnikom) - koristno za cold start, ker imaš veliko vprašajev - delaš tranzitivnost okusa - če je prvi podoben drugemu in drugi podoben tretjemu, potem bo treji dal podobno oceno kot prvi - uporabiš en ali dva skoka, ker potem podobnosti zbledijo

- monolitni sistemi rabijo več efforta od razvijalca, ker spreminjamo malo modele, jih drugače uporabimo
- pri paralelno in zaporedno lahko vzamemo samo off the shelf algoritme (čeprav tudi tu lahko delamo modifikacije)
- prednost monolitnih: ker so custom made, so lahko boljši
- slabost monolit: ni garancije, da ti bo ratalo narediti nekaj boljšega

Mixed hibridi:
- collaborative - so dobri za serendipity (dobimo prijetna presenečenja)
- content based:
	- kot ML, gledaš samo featurje izdelkov in na podlagi tega priporočaš
	- bolj varni pri hladnem zagonu
	- lahko se nam zgodi, da dobivamo more of the same ves čas
- lahko imaš tudi vse modele collaborative, ampak naučene na različnih podatkih
- če imaš npr. da moraš poleg 7 priporočil za filme priporočiti še 2 filma, ki sta pay per view:
	- lahko naredimo en recommender, ki se uči samo na pay per view filmih
- npr. za šport ne želiš recommendati starih tekem, ker tega noben ne gleda, ampak rabiš napovedati prihajajoče ali nedavne tekme
- če je nekdo gledal prvi del filma, bo najbrž gledal tudi sequel - imaš en recommender, priporoča samo sequele filmov, ki si jih gledal:
	- support v primeru povezovalnih pravil ne bo velik, ker večino filmov nima sequela, ampak zaupanje bo veliko
- vsak model naučiš ločeno in potem samo vse združiš (če napoveduješ 9 filmov skupaj, bo vsak model dal npr. dva filma)

Switch:
- preklapljaš med recommenderji
- npr. en recommender je dober za cold start, en je dober, ko imam veliko podatkov (collaborative), en je za ravno vmes (slope one)
- na podlagi nekega pravila izbereš, kater recommender boš izbral v trenutni situaciji

Weighted:
- za vsak recommender dobimo oceno in njegovo zanesljivost (npr. za collaborative nam da zraven število podobnih userjev, za slope one nam da število trojčkov)
- na podlagi zanesljivosti delam voting (lahko tudi samo avg vzamemo)
- lahko en recommender zelo kriči, da ima veliko podobnih userjev in mu daš 90% teže
- prednosti:
	- modelov nič nismo modificirali, zelo enostavno za implementacijo; malo nas stane dodatno delo za implementacijo (pri monolitu smo morali spreminjati recommender - tega običajno ne delaš na novi domeni, ampak začneš s prototipi, ki jih lahko paraleliziraš in potem, ko imaš dovolj znanja, lahko narediš monolit)
- lahko imamo hibridne modele v hibridnih modelih, npr. en recommender med vzporednimi je vzporeden

- npr. novice:
	- taggaš vrsto članka
	- novice so aktualne samo nekaj časa, npr. za volitve ali športne novice
	- dokumentarni članki so zanimivi neomejeno dolgo časa
	- dobiš tagga, ki nam povejo, koliko časa približno bo ta članek relevanten
	- želiš imeti spread člankov, da so vsi različno aktualni
	- switch: če ti ne morem nič aktualnega priporočati, potem priporočaj dokumentarni članek
	- vsak recommender ima različen pool na katerih je bil naučen, glede na tagge (kratkoročni članke, medium, neomejeno časa relevantni)