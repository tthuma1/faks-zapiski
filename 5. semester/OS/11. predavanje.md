- status quo trap:
	- good enough, tudi če imaš izbiro, da zamenjaš svojo odločitev za neko boljšo, je ne boš zamenjal, ker se ti ne da (vseeno rabiš nekaj efforta, čeprav zelo malo)
	- hočeš, da stvari ostanejo tako, kot so sedaj
	- sledi stanju, ki trenutno obstaja
	- npr. če kupuješ delnice, kupiš tisto, ki ti jo nekdo predlaga, brez da bi se pozanimal o ostalih možnostih, ker bi za to rabil effort, in ker je tista ponujena najbrž good enough
	- npr. pri menjavi telefonskega operaterja, ti novi operater hoče olajšati prehod k njim, da je čim manj efforta - če je efforta preveč, se nobenemu ne bo dalo iti k tebi, tudi če si ti boljši
	- npr. prvi avti so bili podobni kočijam, električne polnilnice izgledajo enako kot bencinske, prvi elektronski novičniki so imeli isti dizajn kot fizični
	- npr. pri senatu, ko nekaj predlagaš, prevzameš odgovornost za posledice nase; če si tiho, nimaš nobene odgovornosti
	- kako se izognemo tej pasti:
		- se zavedamo in vložimo effort
		- ni nujno, da je alternativa res boljša - lahko ugotovimo, da je status quo prava izbira

### Hibridizacija priporočilnih sistemov

- podobno kot ensamble pri machine learning - random forest, gradient boosting, kjer vsak model glasuje
- hibridiziramo prvi del priporočilnega sistema, ki nam da številčni output (engine, brez šminke)

Monolitni hibridi:
- priporočilni sistem
- še vedno imaš monolitni sistem (ena celota, brez koščkov)
- recommenderji znotraj monolita bodo še vedno videti kot ena celota
- vhodi se bodo zgrupirali na notranje sistema oz. ustrezno preprocesirali

Paralelni hibridni:
- nimamo enega recommendeerja, ki ga spremenimo, ampak imamo več recommenderjev, kjer ima vsa svoj input (lahko imajo isti input)
- na nek način združimo rezultat
- to je isto kot random forest

Zaporedni hibridni:
- kot XGBoost in ADABOOST
- vsak naslednji recommender dobi za vhod izhod iz prejšnjega (zraven lahko pomešamo še originalen input)
- prvi naredi neko napoved in potem naslednji recommender popravi napoved od prejšnjega
- prvi recommender je lahko hiter (hitra začetna selekcija, ima manj znanja in je manj kvaliteten), naslednji pa počasen (na podani grobi izbiri delamo počasen, natančen recommender, ki je v bistvu dovolj hiter, ker ima veliko manj primerov, med katerimi lahko izbira)

- kombiniranje featurejev

Primer v zvezku:
- navigation - po katerih straneh si gledal
- view - uporabnik je kliknil na izdelek in ga zdaj gleda - velika verjetnost, da mu je bila ta stvar všeč, da je pritegnila njegovo pozornost
- context - k = keyword (kaj konkretno si iskal - si spet moral izraziti ekspliciten trud, torej ti je to najbrž všeč)
- buy - najmočnejša možna podpora, če si nekaj kupil, ti je skoraj zagotovo všeč (se dogaja šum - lahko si kupil za prijatelja)
- nav < view < context < buy
- na tem lahko uporabimo collaborative filtering - kateri uporabniki so podobni trenutnemu uporabniku