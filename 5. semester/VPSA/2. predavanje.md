Sistemi s skupnim pomnilnikom:
- več jeder, kjer ima vsako jedro svoj predpomnilnik (vsaj L1; L2 je lahko deljen ali ne; L3 je že deljen)
- temu rečemo UMA - vsa procesorska jedra rabijo enako časa, da dostopajo do pomnilnika
- če dve jedri dostopata do istega naslova naenkrat, se bosta morali čakati
- rečemo tudi SMP (symmetric multiprocessor)
- težave:
	- ni raztegljiva, smo omejeni s številom jeder (pod 10)

Problem skladnosti predpomnilnikov:
- dve jedri nek podatek cachata in eno jedro ga spremeni v cachu, v drugem predpomnilniku pa je še vedno star podatek
- write through in write back za pisanje v glavni pomnilnik
- write through:
	- takoj ob spremembi zapišemo tudi v glavni pomnilnik
	- ob tem lahko ostali predpomnilniki vidijo, da se ta naslov spreminja, ker je vse na skupnem vodilu in razveljavi svoj podatek (lahko bi tudi takoj vzel nov podatek, ampak ponavadi samo razveljavi starega)
	- ustvari veliko prometa na vodilu - do okoli 4 jedra

NUMA (Non Uniform Memory Access):
- še vedno imamo enovit naslovni postor (isti kos pomnilnika vedno naslovimo z istim naslovom)
- vsi procesorji lahko dostopajo do kateregakoli kosa pomnilnika
- dostopni časi niso več vedno enaki:
	- če do svojega pomnilnika rabiš 1 enoto, boš rabil do ostalih 2 do 3 enote
- lahko tudi naredimo, da si več jeder deli en pomnilnik, in je potem razdeljen med skupinami jeder (več jeder isto hitro dostopa do enega kosa pomnilnika)
- uporabimo write back:
	- imamo D (direktorij) pomnilnik, ki nam pove, kaj se je zgodilo z nekim delom pomnilnika
	- MESI zastavice - modified, exclusive, shared, invalidated:
		- modified - ko spremeniš
		- exclusive - samo za en procesor
		- shared - ima ga več procesorjev (nek drug procesor ga je prebral v svoj cache)
		- invalidated - en procesor je spremenil pri svojem cachu, zato ga moraš razveljaviti pri sebi
	- vsakič, ko želi procesor brati podatek, mora najprej v direktoriju pogledati zastavice
- manj obremeni vodilo - lahko dodamo več jeder
- več jeder lahko hkrati dostopa do različnih delov pomnilnika

Sistemi s porazdeljenim pomnilnikom:
- prvi superračunalniki so bili vektorski (SIMD) - lahko skupaj delajo nad več elementi vektorja (tabele), npr. hkrati sešteješ vse elemente dveh vektorjev na istoležnih indeksih:
	- so super za znanstvene simulacije, ampak razvoj je drag
	- ugotovijo, da osebni računalniki v bistvu niso tako slabi
- kupimo več osebnih računalnikov in jih povežemo skupaj v mrežo:
	- rabiš še software, ki zna naloge porazdeliti med sisteme
	- mreža je bistveno počasnejše vodilo, ampak je vseeno bolje od superskalarnih
- naslovni prostor NI enovit:
	- da procesorji komunicirajo si morajo pošiljati sporočila po mreži
	- da si drugi procesor posodobi pomnilnik s podatki iz prvega procesorja, se mora strinjati z njegovim sporočilom
	- rabimo omrežni protokoll za stežnik in odjemalec

Uporaba grafičnih kartic:
- "accelerator", grafični pospeševalniki
- glavni del se dogaja na procesorju, za operacije za katere predvidi, da se bodo hitreje izvajale na GPU, jih pošlje tja
- koraki za prenos podatkov:
	- procesor shrani podatek v glavni pomnilnik
	- podatke moramo poslati iz glavnega pomnilnika na grafično kartico
	- procesor sproži računanje na GPU
	- podatke dobimo nazaj iz grafične kartice v glavni pomnilnik
- uporabno, ko lahko enkrat pošljemo veliko podatkov, potem pa dolgo računamo z njimi
- zakaj so GPU hitrejše:
	- vedno delamo vzporedne operacije nad ogromno podatki
	- rabimo ustrezen problem - računanje barve za vsak piksel je neodvisno med sabo; učenje nevronskih mrež je podobno
	- kontrolna enota je zelo primitivna, večji del silicija zavzamejo ALE
- na začetku v GPU ni bilo predpomnilnika:
	- stavimo na to, da imamo tako veliko opravil, da med tem, ko eno opravilo fetcha podatke iz pomnilnika, se druga opravila računajo
- navaden CPU ima vedno sekvenčna opravila in potem išče vzorce, da ugotovi kaj se da paralelizirati

- danes imamo v superračunalnikih večjedrne procesorje (NUMA) + GPU, ki so povezani v mrežo:
	- če pogledamo od daleč je sistem s porazdeljenim pomnilnikom, ampak v bistvu je mešanica vsega

- primer AMD: imamo štiri NUMA domene, vsaka je iz dveh silicijevih rezin, ki ima po dva paketa procesorjev s štirimi jedri => 16 jeder dostopa do enega dela pomnilnika (enaki dostopni časi)

- MPP - massively powered processors:
	- so še vedno gruče, ampak malo drugačne

### Operacijski sistem

Naloge:
- upravlja s pomnilnikom
- skrbi z V/I napravami
- dela z datotečnim sistemom (vzpostavitev, nadzor dostopa)
- varnostne funkcije za večuporabniške sisteme (en uporabnik ne more upravljati s procesi drugega uporabnika)
- razporejanje opravil (procesov) med jedra

- večuporabniški in večopravilni (več procesov naenkrat lahko obstaja)
- več procesov teče sočasno tako, da se zelo hitro preklaplajo na procesorju (v bistvu ne tečejo hkrati, ampak se nam samo zdi, ker jih OS tako hitro preklaplja)
- sočasno = hitro preklapljanje
- preklapljanje konteksta nas stane, ker si moramo shraniti registre, file handlerje (procesno sliko) ..., da ko proces pride nazaj, ve od kje mora nadaljevati
- proces je program v izvajanju; program je samo neka koda:
	- ko želimo pognati nek program, najprej OS pripravi stvari, ki so potrebne za proces, potem pa začne izvajati program
	- lahko večkrat zaženemo program - dobimo več procesov

- ker je preklapljanje med procesi počasno, imamo še niti
- nit = osnovna enota, ki ji OS lahko dodeljuje vire in jo izvaja (razvršča); lightweight proces
- znotraj enega procesa imamo lahko več niti

- primer večnitnosti:
	- za odziven uporabniški vmesnik ga damo v drugo nit - tista nit je ves čas odzivna

- iz glavne niti naredimo novo nit s fork
- pridružimo nit nazaj z join

- kdo se odloča katera nit se izvaja:
	- niti razvršča OS, na to mi nimamo vpliva
	- programe moramo pisati tako, da ne vemo, katera nit se izvaja
	- imamo sočasen in vzporeden program, ker se različne niti lahko dejansko vzporedno izvajajo

- pišemo programe, ki se znajo izvajati na eni niti, ampak jih znajo izkoristiti tudi več
- niti si delijo pomnilnik:
	- niti imajo skupno kopico in globalne spremenljivke
	- vsaka nit ima svoj sklad, ker imajo drugačne klice funkcij
	- zato je ceneje preklapljati med nitmi kot med procesi, ker si rabimo manj podatkov shraniti

- če nit ne more nadaljevati z izvajanjem, jo umaknemo iz procesorja:
	- če nit čaka na vire, postane blokirana

- sočasnost je programski vzorec
- `pthreads` knjižnica v C za niti
- deli in vladaj algoritme se da lepo vzporedno napisati:
	- dobimo različno velike kose in bomo težko vse niti enako obremenili
	- nitim dodamo še en nivo abstrakcije - naloge (tasks)

Naloge (tasks):
- problem lahko lepo sočasno sprogramiramo, ampak posamezni kosi dela so med seboj zelo različni
- naloge razvršča program - imamo že napisan programski razvrščevalnik v knjižnici
- programski razvrščevalnik se odloča katero nalogo bo izvedel, kateri niti jo bo dal; če je naloga blokirana jo bo dal spat
- zelo hitro lahko damo eni niti drugo nalogo brez da OS opazi, da je neka nit blokirana
- za niti se odloča razvrščevalnik OS, za naloge se odloča programski razvrščevalnik
- spet ne vemo vrstnega reda, v katerem se bodo naloge izvajale - moramo programirati tako, da bodo naloge v pravem vrstnem redu (oz. da ena naloga čaka dokler ne dobi ustreznih vhodnih podatkov)

- lahko imamo neomejeno število nalog (več kot jih je, bolje dela običajno)
- količina niti je običajno manjš, običajno imamo toliko niti kot jeder, da ni treba preklapljati niti na enem jedru (to nas bi stalo)

- tudi preklapljanje med nalogami nas stane, ampak še manj kot med nitmi; ustvarjanje in zaključevanje nalog nas manj stane kot pri nitih
- naloge v Go = goroutine

### Gruče
- za razporejanje poslov na gruči rabimo vmesno programsko opremo

- prijavno vozlišče vidi datotečni sistem enako kot računska vozlišča